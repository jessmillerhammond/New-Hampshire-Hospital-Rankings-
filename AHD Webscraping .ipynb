{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of Hospital URLS for hospitals in United States from American Hospital Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## URL for search of just US States. Returns 6962 Hostpitals\n",
    "#### https://www.ahd.com/list_cms.php?submitted=Submit&mname=&mcity=&mstate%5B%5D=AK&mstate%5B%5D=AL&mstate%5B%5D=AR&mstate%5B%5D=AS&mstate%5B%5D=AZ&mstate%5B%5D=CA&mstate%5B%5D=CO&mstate%5B%5D=CT&mstate%5B%5D=DC&mstate%5B%5D=DE&mstate%5B%5D=FL&mstate%5B%5D=GA&mstate%5B%5D=HI&mstate%5B%5D=IA&mstate%5B%5D=ID&mstate%5B%5D=IL&mstate%5B%5D=IN&mstate%5B%5D=KS&mstate%5B%5D=KY&mstate%5B%5D=LA&mstate%5B%5D=MA&mstate%5B%5D=MD&mstate%5B%5D=ME&mstate%5B%5D=MI&mstate%5B%5D=MN&mstate%5B%5D=MO&mstate%5B%5D=MS&mstate%5B%5D=MT&mstate%5B%5D=NC&mstate%5B%5D=ND&mstate%5B%5D=NE&mstate%5B%5D=NH&mstate%5B%5D=NJ&mstate%5B%5D=NM&mstate%5B%5D=NV&mstate%5B%5D=NY&mstate%5B%5D=OH&mstate%5B%5D=OK&mstate%5B%5D=OR&mstate%5B%5D=PA&mstate%5B%5D=RI&mstate%5B%5D=SC&mstate%5B%5D=SD&mstate%5B%5D=TN&mstate%5B%5D=TX&mstate%5B%5D=UT&mstate%5B%5D=VA&mstate%5B%5D=VT&mstate%5B%5D=WA&mstate%5B%5D=WI&mstate%5B%5D=WV&mstate%5B%5D=WY&mzip=&mphone=\n",
    "\n",
    "\n",
    "urllist = \"https://www.ahd.com/list_cms.php?submitted=Submit&mname=&mcity=&mstate%5B%5D=AK&mstate%5B%5D=AL&mstate%5B%5D=AR&mstate%5B%5D=AS&mstate%5B%5D=AZ&mstate%5B%5D=CA&mstate%5B%5D=CO&mstate%5B%5D=CT&mstate%5B%5D=DC&mstate%5B%5D=DE&mstate%5B%5D=FL&mstate%5B%5D=GA&mstate%5B%5D=HI&mstate%5B%5D=IA&mstate%5B%5D=ID&mstate%5B%5D=IL&mstate%5B%5D=IN&mstate%5B%5D=KS&mstate%5B%5D=KY&mstate%5B%5D=LA&mstate%5B%5D=MA&mstate%5B%5D=MD&mstate%5B%5D=ME&mstate%5B%5D=MI&mstate%5B%5D=MN&mstate%5B%5D=MO&mstate%5B%5D=MS&mstate%5B%5D=MT&mstate%5B%5D=NC&mstate%5B%5D=ND&mstate%5B%5D=NE&mstate%5B%5D=NH&mstate%5B%5D=NJ&mstate%5B%5D=NM&mstate%5B%5D=NV&mstate%5B%5D=NY&mstate%5B%5D=OH&mstate%5B%5D=OK&mstate%5B%5D=OR&mstate%5B%5D=PA&mstate%5B%5D=RI&mstate%5B%5D=SC&mstate%5B%5D=SD&mstate%5B%5D=TN&mstate%5B%5D=TX&mstate%5B%5D=UT&mstate%5B%5D=VA&mstate%5B%5D=VT&mstate%5B%5D=WA&mstate%5B%5D=WI&mstate%5B%5D=WV&mstate%5B%5D=WY&mzip=&mphone=\"\n",
    "urlsite = urlopen(urllist)\n",
    "urlsoup = BeautifulSoup(urlsite.read(), \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = urlsoup.findAll(\"tr\", {\"class\":{\"b\", \"\"}}) \n",
    "    \n",
    "listofhosp = []\n",
    "\n",
    "\n",
    "for hosp in site:\n",
    "    if 'href'[1] in hosp.attrs:\n",
    "        listofhosp.append(\"https://www.ahd.com\"+current.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(listofhosp, columns=[\"Links\"])\n",
    "df.to_csv('hospitallinks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function scrapes the tables on the hospital profile page on the AHD website and saves as csv files.  This information will be used in cluster analysis for hospitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getprofile(hospitallink):\n",
    "    \n",
    "    hospital = hospitallink\n",
    "    # We will want the above to eventually be a list of all US Hospital URLs.\n",
    "\n",
    "    site = urlopen(hospital)\n",
    "    soup = BeautifulSoup(site.read(), \"html.parser\")\n",
    "\n",
    "    ### Regular expression to extract the 6 digit CMS code from the URL (used to name the csvs later)\n",
    "    match = re.search(r'(?<!\\d)\\d{6}(?!\\d)', hospital)\n",
    "    csvname = (match.group(0))\n",
    "    \n",
    "    \n",
    "    ### This scrapes Identification and characteristics table \n",
    "\n",
    "    rows = soup.findAll(\"tr\")\n",
    "\n",
    "    lists = []\n",
    "    for x in rows:\n",
    "        cells = x.findAll(\"td\")\n",
    "        lis = []\n",
    "        for j in cells:\n",
    "            Q = j.get_text()\n",
    "            str_cells = str(Q)\n",
    "            clean = re.compile(\"<.*?>\")\n",
    "            clean2 = (re.sub(clean, \"\",str_cells))\n",
    "            lis.append(clean2.replace(\"\\n\", \" \"))\n",
    "        lists.append(lis)\n",
    "\n",
    "\n",
    "    lists\n",
    "\n",
    "    K = lists[4]\n",
    "    R = pd.DataFrame(K)\n",
    "    R\n",
    "    S = R.drop(R.index[[0,9,10,17,18, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]])\n",
    "    S\n",
    "\n",
    "\n",
    "    T = S.iloc[::2]\n",
    "    T1 = T.reset_index().drop([\"index\"], axis = 1)\n",
    "    T1.rename(columns = {0: \"Attributes\"}, inplace = True)\n",
    "    T1\n",
    "\n",
    "\n",
    "    U = S.iloc[1::2]\n",
    "    U1 = U.reset_index().drop([\"index\"], axis = 1)\n",
    "    U1\n",
    "\n",
    "\n",
    "    T1['Details'] = U1[0]\n",
    "    \n",
    "    T1.to_csv(csvname+\"_HospChar.csv\")\n",
    "    \n",
    "    #Inpatient Utilization Table SCRAPES ALL NEEDED INFORMATION\n",
    "\n",
    "    inpatientutil = soup.find(\"a\", {\"name\":\"inpatientstats\"})\n",
    "    inpatstats = inpatientutil.find_next(\"table\")\n",
    "\n",
    "    headerlist = ['', 'Number Medicare Inpatients', 'Average Length of Stay', 'Average Charges', 'Medicare Case Mix Index (CMI)']\n",
    "    deptlist = []\n",
    "    numpats = []\n",
    "    avgstay = []\n",
    "    avgcharge = []\n",
    "    cmiindex = []\n",
    "\n",
    "    #For loop starts at 1 because first row is headers which is different from other trs so it won't work.\n",
    "    for statistics in inpatstats.findAll(\"tr\")[1:]:\n",
    "        data = statistics.findAll(\"td\")\n",
    "        deptlist.append(data[0].text)\n",
    "        numpats.append(data[1].text)\n",
    "        avgstay.append(data[2].text)\n",
    "        avgcharge.append(data[3].text)\n",
    "        cmiindex.append(data[4].text)\n",
    "        \n",
    "    ####Inputting inpatient utilization into a dataframe.\n",
    "\n",
    "    InpatData = pd.DataFrame({headerlist[0]:deptlist, headerlist[1]:numpats, headerlist[2]:avgstay,\n",
    "                             headerlist[3]:avgcharge, headerlist[4]:cmiindex})\n",
    "\n",
    "    InpatData.to_csv(csvname+\"_InpatData.csv\", index = False)\n",
    "    \n",
    "    \n",
    "    ###Inpatient origin for top 3 ZIP Codes\n",
    "\n",
    "    inpatientorigin = soup.find(\"a\", {\"name\":\"inpatientorigin\"})\n",
    "    originstats = inpatientorigin.find_next(\"table\")\n",
    "\n",
    "    originheaders = ['ZIP Code of Residence', 'Discharges', 'Days of Care', 'Charges', 'Discharges Inc/(Dec)', 'Market Share']\n",
    "    zipres = []\n",
    "    dischargelist = []\n",
    "    numberdays = []\n",
    "    chgs = []\n",
    "    changedischg = []\n",
    "    mktshare = []\n",
    "\n",
    "    #For loop starts at 1 because first row is headers which is different from other trs so it won't work.\n",
    "    for ostats in originstats.findAll(\"tr\")[1:]:\n",
    "        origindata = ostats.findAll(\"td\")\n",
    "        zipres.append(origindata[0].text)\n",
    "        dischargelist.append(origindata[1].text)\n",
    "        numberdays.append(origindata[2].text)\n",
    "        chgs.append(origindata[3].text)\n",
    "        changedischg.append(origindata[4].text)\n",
    "        mktshare.append(origindata[5].text)\n",
    "        \n",
    "        \n",
    "    ####Inputting origin for top 3 zips into a dataframe. \n",
    "\n",
    "    OriginPatData = pd.DataFrame({originheaders[0]:zipres, originheaders[1]:dischargelist, originheaders[2]:numberdays,\n",
    "                                 originheaders[3]:chgs, originheaders[4]:changedischg, originheaders[5]:mktshare})\n",
    "    \n",
    "    OriginPatData.to_csv(csvname+\"_IPOrigin.csv\", index = False)\n",
    "    \n",
    "    \n",
    "    ### Scraping outpatient utilization.\n",
    "\n",
    "    OPheader = soup.find(\"a\", {\"name\":\"outpatientstats\"})\n",
    "    OPstats = OPheader.find_next(\"table\")\n",
    "\n",
    "    opheads = ['APC Number', 'APC Description', 'Number Patient Claims', 'Average Charge', 'Average Cost']\n",
    "    apcnum = []\n",
    "    apcdesc = []\n",
    "    numclaims = []\n",
    "    opcharge = []\n",
    "    opcost = []\n",
    "\n",
    "    #For loop starts at 1 because first row is headers which is different from other trs so it won't work.\n",
    "    for op in OPstats.findAll(\"tr\")[1:]:\n",
    "        opdata = op.findAll(\"td\")\n",
    "        apcnum.append(opdata[0].text)\n",
    "        apcdesc.append(opdata[1].text)\n",
    "        numclaims.append(opdata[2].text)\n",
    "        opcharge.append(opdata[3].text)\n",
    "        opcost.append(opdata[4].text)\n",
    "        \n",
    "        \n",
    "    ####Inputting outpatient utilization into a dataframe. \n",
    "\n",
    "    OPUtilData = pd.DataFrame({opheads[0]:apcnum, opheads[1]:apcdesc, opheads[2]:numclaims,\n",
    "                                 opheads[3]:opcharge, opheads[4]:opcost})\n",
    "    \n",
    "    \n",
    "    OPUtilData.to_csv(csvname+\"_OpUtilData.csv\", index = False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## Beds and Patient Days by Unit\n",
    "\n",
    "    bedsheader = soup.find(\"a\", {\"name\":\"bedsdaysbyunit\"})\n",
    "    bedsstats = bedsheader.find_next(\"table\")\n",
    "\n",
    "    bedheads = [' ', 'Available Beds', 'Inpatient Days']\n",
    "    unitlist = []\n",
    "    availbeds = []\n",
    "    inpatdays = []\n",
    "\n",
    "    #For loop starts at 1 because first two rows is headers which is different from other trs so it won't work.\n",
    "    for bed in bedsstats.findAll(\"tr\")[2:]:\n",
    "        beddata = bed.findAll(\"td\")\n",
    "        unitlist.append(beddata[0].text)\n",
    "        availbeds.append(beddata[1].text)\n",
    "        inpatdays.append(beddata[2].text)\n",
    "        \n",
    "    ####Inputting beds/patient days into a dataframe. \n",
    "   \n",
    "\n",
    "    BedDaysData = pd.DataFrame({bedheads[0]:unitlist, bedheads[1]:availbeds, bedheads[2]:inpatdays})\n",
    "\n",
    "    BedDaysData.to_csv(csvname+\"_BedDaysData.csv\", index = False)\n",
    "    \n",
    "    \n",
    "    #Financial Statistics\n",
    "\n",
    "    finheader = soup.find(\"a\", {\"name\":\"financialstats\"})\n",
    "    finstats = finheader.find_next(\"table\")\n",
    "\n",
    "    finheads = [' ', 'Available Beds', 'Inpatient Days']\n",
    "    revtypes = []\n",
    "    dollars = []\n",
    "    percentages = []\n",
    "\n",
    "    #For loop starts at 1 because first two rows is headers which is different from other trs so it won't work.\n",
    "    for fins in finstats.findAll(\"tr\")[1:]:\n",
    "        findata = fins.findAll(\"td\")\n",
    "        revtypes.append(findata[0].text)\n",
    "        dollars.append(findata[1].text)\n",
    "        percentages.append(findata[2].text)\n",
    "        \n",
    "    ####Inputting financial stats into a dataframe. LOOKS GOOD\n",
    "\n",
    "    FinData = pd.DataFrame({finheads[0]:revtypes, finheads[1]:dollars, finheads[2]:percentages})\n",
    "    \n",
    "    #Writing FinData to csv.\n",
    "    FinData.to_csv(csvname+\"_FinData.csv\", index = False)\n",
    "    \n",
    "    print(FinData)\n",
    "    print(T1)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through the links 3 hospitals at a time (more than three at a time will lead to errors due to captchas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hospitallinks = pd.read_csv(\"D:/My Passport/Courses/UNH/Fall 2018/Health Analytics 812/links.csv\")\n",
    "\n",
    "# hospitallinks\n",
    "\n",
    "for i in range(27, 29):\n",
    "    getprofile(hospitallinks[\"Links\"][i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
